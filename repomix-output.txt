This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.github/
  workflows/
    ci.yaml
app/
  main.py
  requirements.txt
terraform/
  main.tf
  variables.tf
.gitignore
Dockerfile
LICENSE
README.md

================================================================
Files
================================================================

================
File: .github/workflows/ci.yaml
================
name: CI

on:
  push:
    branches:
      - main
  pull_request:

env:
  ENVIRONMENT: production

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.7

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::724772086697:role/GitHubActionsECRRole
          aws-region: us-east-1

      - name: Login to Amazon ECR
        run: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 724772086697.dkr.ecr.us-east-1.amazonaws.com
        working-directory: .

      - name: Initialize Terraform
        run: terraform init -upgrade -reconfigure
        working-directory: terraform

      - name: Build Docker image
        run: |
          docker build --no-cache -t aws-devops-demo -f Dockerfile .
          docker run --rm aws-devops-demo bash -c "pip list" > pip_list.txt
          cat pip_list.txt
          if ! grep -i "requests" pip_list.txt; then
            echo "Error: requests module not found in image"
            exit 1
          fi
          if ! grep -i "boto3" pip_list.txt; then
            echo "Error: boto3 module not found in image"
            exit 1
          fi
          rm pip_list.txt
        working-directory: .

      - name: Tag and push Docker image to ECR
        run: |
          IMAGE_TAG=$(echo $GITHUB_SHA | cut -c1-7)
          ECR_URI=724772086697.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/aws-devops-demo
          docker tag aws-devops-demo:latest $ECR_URI:$IMAGE_TAG
          docker tag aws-devops-demo:latest $ECR_URI:latest
          docker push $ECR_URI:$IMAGE_TAG
          docker push $ECR_URI:latest
        env:
          IMAGE_TAG: ${{ env.IMAGE_TAG }}

      - name: Apply Terraform
        run: terraform apply -auto-approve
        working-directory: terraform

================
File: app/main.py
================
from flask import Flask
import boto3
import os
import logging
import time
from botocore.exceptions import ClientError

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

AWS_REGION = os.getenv('AWS_REGION', 'us-east-1')

def get_dynamodb():
    max_retries = 15
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            logger.info(f"Attempt {attempt+1}/{max_retries} to connect to DynamoDB")
            # Use default IMDSv2 handling without imds_client_config
            dynamodb = boto3.resource('dynamodb', region_name=AWS_REGION)
            # Test connection
            dynamodb.meta.client.list_tables()
            logger.info("DynamoDB connection successful")
            return dynamodb
        except ClientError as e:
            error_code = e.response.get('Error', {}).get('Code', '')
            error_msg = e.response.get('Error', {}).get('Message', str(e))
            logger.error(f"DynamoDB client error: {error_code} - {error_msg}")
            if error_code in ['AccessDenied', 'UnauthorizedOperation']:
                logger.error("Permissions issue detected")
            if attempt < max_retries - 1:
                logger.info(f"Retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
            else:
                logger.error("Max retries reached for DynamoDB connection")
                raise
        except Exception as e:
            logger.error(f"Unexpected error connecting to DynamoDB: {str(e)}")
            if attempt < max_retries - 1:
                logger.info(f"Retrying in {retry_delay} seconds...")
                time.sleep(retry_delay)
            else:
                logger.error("Max retries reached for DynamoDB connection")
                raise

try:
    dynamodb = get_dynamodb()
    table = dynamodb.Table('DemoHits')
    logger.info("DynamoDB connection initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize DynamoDB: {str(e)}")
    dynamodb = None
    table = None

@app.route("/")
def index():
    global dynamodb, table
    if table is None:
        try:
            logger.info("Attempting to reinitialize DynamoDB connection")
            dynamodb = get_dynamodb()
            table = dynamodb.Table('DemoHits')
            logger.info("DynamoDB connection reinitialized successfully")
        except Exception as e:
            logger.error(f"Failed to reinitialize DynamoDB: {str(e)}")
            return "Application experiencing database connectivity issues. Please try again later.", 500
    try:
        logger.info("Updating DynamoDB hit counter")
        # Increment hit counter in DynamoDB
        response = table.update_item(
            Key={'id': 'hit_counter'},
            UpdateExpression="SET hit_count = if_not_exists(hit_count, :start) + :inc",
            ExpressionAttributeValues={':start': 0, ':inc': 1},
            ReturnValues="UPDATED_NEW"
        )   # Atomic increment with default value
        count = response['Attributes']['hit_count']
        logger.info(f"Successfully updated counter to {count}")
        return f"Welcome to my AWS DevOps Demo! Page Hits: {int(count)}"
    except Exception as e:
        logger.error(f"Error updating hit counter: {str(e)}")
        return "Application experiencing database connectivity issues. Please try again later.", 500

@app.route("/health")
def health():
    logger.info("Health check passed")
    return "OK", 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)

================
File: app/requirements.txt
================
Flask>=2.1.0
Werkzeug>=2.1.0
boto3>=1.34.0
requests>=2.31.0,<3.0.0

================
File: terraform/main.tf
================
# Terraform Configuration for AWS DevOps Demo
# Defines the provider, backend, and resource dependencies for a production-ready ECS deployment
terraform {
  # Configure required providers with version constraints
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"  # Use latest 5.x series for stability and features
    }
  }
  # Specify compatible Terraform version
  required_version = "~> 1.5.7"

  # S3 backend for remote state management
  backend "s3" {
    bucket         = "aws-devops-demo-terraform-state"
    key            = "aws-devops-demo/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
  }
}

# AWS Provider Configuration
# Sets the default region for all AWS resources
provider "aws" {
  region = var.aws_region
}

# ---------------------------------------------
# Networking Resources
# Defines the VPC, subnets, and routing for the application

# VPC for the DevOps Demo
resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
  tags = {
    Name        = "devops-demo-vpc"
    Environment = "production"
  }
}

# Public Subnets for Load Balancer and ECS
resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, count.index)
  map_public_ip_on_launch = true
  availability_zone       = element(["us-east-1a", "us-east-1b"], count.index)
  tags = {
    Name        = "devops-demo-subnet-public-${count.index}"
    Environment = "production"
  }
}

# Internet Gateway for Public Access
resource "aws_internet_gateway" "gw" {
  vpc_id = aws_vpc.main.id
  tags = {
    Name        = "devops-demo-igw"
    Environment = "production"
  }
}

# Route Table for Public Subnets
resource "aws_route_table" "public_rt" {
  vpc_id = aws_vpc.main.id
  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.gw.id
  }
  tags = {
    Name        = "devops-demo-public-rt"
    Environment = "production"
  }
}

# Associate Route Table with Public Subnets
resource "aws_route_table_association" "public_assoc" {
  count          = length(aws_subnet.public[*].id)
  subnet_id      = aws_subnet.public[count.index].id
  route_table_id = aws_route_table.public_rt.id
}

# ---------------------------------------------
# Storage Resources
# Manages ECR and DynamoDB for the application

# ECR Repository for Docker Images
resource "aws_ecr_repository" "devops_demo_repo" {
  name                 = "aws-devops-demo"
  image_tag_mutability = "MUTABLE"
  encryption_configuration {
    encryption_type = "AES256"
  }
  tags = {
    Name        = "devops-demo-ecr"
    Environment = "production"
  }
}

# DynamoDB Table for Hit Counter
resource "aws_dynamodb_table" "demo_hits" {
  name           = "DemoHits"
  billing_mode   = "PAY_PER_REQUEST"  # Cost-effective for demo
  hash_key       = "id"
  attribute {
    name = "id"
    type = "S"
  }
  tags = {
    Name        = "devops-demo-hits"
    Environment = "production"
  }
}

# ---------------------------------------------
# Security Resources
# Defines security groups and IAM roles for access control

# Security Group for Application Load Balancer
resource "aws_security_group" "alb_sg" {
  name_prefix = "alb-sg-"
  vpc_id      = aws_vpc.main.id
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]  # Allow public HTTP access
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  tags = {
    Name        = "devops-demo-alb-sg"
    Environment = "production"
  }
}

# Security Group for ECS Tasks
resource "aws_security_group" "ecs_sg" {
  name_prefix = "ecs-sg-"
  vpc_id      = aws_vpc.main.id
  ingress {
    from_port       = 5001
    to_port         = 5001
    protocol        = "tcp"
    security_groups = [aws_security_group.alb_sg.id]  # Restrict to ALB traffic
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  tags = {
    Name        = "devops-demo-ecs-sg"
    Environment = "production"
  }
}

# IAM OpenID Connect Provider for GitHub Actions
data "aws_caller_identity" "current" {}

resource "aws_iam_openid_connect_provider" "github_actions" {
  url             = "https://token.actions.githubusercontent.com"
  client_id_list  = ["sts.amazonaws.com"]
  thumbprint_list = ["6938fd4d98bab03faadb97b34396831e3780aea1"]
}

# IAM Role for GitHub Actions
resource "aws_iam_role" "github_actions_role" {
  name = "GitHubActionsECRRole"
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Federated = "arn:aws:iam::${data.aws_caller_identity.current.account_id}:oidc-provider/token.actions.githubusercontent.com"
      }

================
File: terraform/variables.tf
================
variable "aws_region" {
  type    = string
  default = "us-east-1"
}

variable "ecs_task_family" {
  type    = string
  default = "devops-demo-task"
}

variable "image_tag" {
  type    = string
  default = "latest"
}

================
File: .gitignore
================
venv/
.terraform/
.terraform.lock.hcl
.terraform/
terraform.tfstate*

================
File: Dockerfile
================
# Use a lightweight Python 3 base image
FROM python:3.9-slim

# Set working directory
WORKDIR /app

# Install system dependencies (optional, for future-proofing)
RUN apt-get update && apt-get install -y \
  gcc \
  && rm -rf /var/lib/apt/lists/*

# Copy requirements first so Docker can cache this layer
COPY app/requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the app
COPY app/ /app/

# Expose the port for Flask
EXPOSE 5001

# Command to start the Flask app
CMD ["python", "main.py"]

================
File: LICENSE
================
MIT License

Copyright (c) 2025 Paul Yi

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: README.md
================
# AWS DevOps Demo

![CI Workflow](https://github.com/paulcyi/aws-devops-demo/actions/workflows/ci.yaml/badge.svg?branch=main&event=push)
![Build](https://img.shields.io/badge/Build-Passing-green)  
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

Welcome to the AWS DevOps Demo! This project showcases a scalable web application hosted on AWS Elastic Container Service (ECS) using Fargate, featuring a live DynamoDB-based hit counter. It demonstrates CI/CD with GitHub Actions, Docker containerization, and Terraform for infrastructure as code (IaC). Built as my first DevOps GitHub makeover project, it highlights my skills in cloud infrastructure, automation, and problem-solving.

## Live Counter
Check out the live hit counter in action:  
[View Live Counter](http://devops-demo-alb-426352306.us-east-1.elb.amazonaws.com/)  


![Counter Screenshot](counter_screenshot.png)  


## Project Overview
This project is a hands-on implementation of a DevOps workflow, leveraging AWS services to deploy a Python Flask application. The hit counter increments with each page visit, stored in Amazon DynamoDB, and served via an Application Load Balancer (ALB) on ECS with Fargate. The infrastructure is defined using Terraform, with automated builds and deployments managed by GitHub Actions. Key challenges overcome include backend state drift, IAM policy scoping, and container dependency management.

## Technologies Used
- **Languages/Frameworks**: Python (Flask), Docker
- **Cloud Services**: AWS (ECS, Fargate, ALB, DynamoDB, IAM, S3, CloudWatch, ECR)
- **Infrastructure as Code**: Terraform
- **CI/CD**: GitHub Actions
- **Skills Demonstrated**: CI/CD pipelines, container orchestration, IaC, cloud security, troubleshooting (e.g., fixing S3 backend issues, IAM permissions).

## Installation and Usage
### Local Setup
1. **Create a Virtual Environment**:
   ```bash
   python3 -m venv venv

2. **Activate the Virtual Environment**:
- macOS/Linux: `source venv/bin/activate`
- Windows: `venv\Scripts\activate`

3. **Install Dependencies**:
   ```bash
   pip install -r app/requirements.txt

4. **Build and Run Docker Locally:**
   ```bash
   docker build -t aws-devops-demo -f Dockerfile .
   docker run -p 5001:5001 aws-devops-demo

5. **Access the Counter**:
- Open `http:localhost:5001` in your browser.


### Prerequisites
- AWS CLI configured with appropriate credentials.
- Docker installed locally.
- Terraform installed (version 1.5.7 recommended).

## Architecture Diagram
```mermaid
graph TD
    A[GitHub Actions] --> B[ECR]
    B --> C[ECS Fargate]
    C --> D[DynamoDB]
    E[ALB] --> C
    F[User] --> E
    G[CloudWatch] --> C
    H[SNS Alerts] --> G
```

*(This Mermaid diagram shows the flow: GitHub Actions builds and pushes to ECR, ECS runs the container with DynamoDB, ALB routes traffic, and CloudWatch/SNS monitor.)*


## Contributing

Feel free to submit pull requests or issues! Please follow these guidelines:

- Fork the repository.
- Create a feature branch (`git checkout -b feature/new-feature`).
- Commit changes (`git commit -m 'Add new feature'`).
- Push and open a pull request.


## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


## Acknowledgements
- Thanks to the xAI Grok team for guidance in building this project.
- Inspired by AWS DevOps best practices and community resources.



================================================================
End of Codebase
================================================================
